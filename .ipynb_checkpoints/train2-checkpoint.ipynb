{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f52322-e1c6-400a-aba1-07f4ead0d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##WITH RMSPROP OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd21fa0-a7a5-4af0-ba2d-e1c7a54061a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b126d8ac-5523-4238-818a-7927319cd2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2210 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data = tf.keras.utils.image_dataset_from_directory('Dataset')\n",
    "data = data.map(lambda x, y: (x / 255, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aabdad9-8725-42c3-ae0a-9e83f7c514d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_size = int(len(data) * 0.7)\n",
    "val_size = int(len(data) * 0.2)\n",
    "test_size = int(len(data) * 0.1)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size + val_size).take(test_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abce731-f381-4ca1-939e-7486b18112cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c3f164-6533-4c21-968a-4e44375acd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16,(3,3),1,activation='relu',input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3),1,activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3),1,activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(4,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb584854-6b67-48eb-aed9-2e24a1810abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6938f4d8-b7af-454c-8fd8-92e771cd117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m18/49\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.2887 - loss: 1.4535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train, epochs=10, validation_data=val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfaaaa7-4daa-43ef-adb7-dbd092e18e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e4e6b-b12e-4b90-bc03-f3da482ab509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9c270-151b-480a-8fed-a2e067b3043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa8f786-b25f-4b88-8a93-e817ffac6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model2.h5')\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323f857-c5be-4725-86b2-400e9fe11e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(prediction):\n",
    "    classes = [\"Bus\", \"Car\", \"Motorcycle\", \"Truck\"]\n",
    "    return classes[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af293f-b2e0-4412-84ef-bc0f7954d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('test.png')\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "np.expand_dims(resize, 0)\n",
    "prediction = model.predict(np.expand_dims(resize / 255, 0))\n",
    "\n",
    "object_class = get_class(prediction[0])\n",
    "confidence = np.max(prediction)\n",
    "\n",
    "print(f\"Predicted Object: {object_class}, Confidence: {confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78362ccd-d2d6-4e04-bb61-69e421618043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (256, 256))  # Assuming your model expects input size of 256x256\n",
    "    image = image.astype('float32') / 255  # Normalize pixel values to [0, 1]\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "test_image_folder = 'test_images'\n",
    "\n",
    "class_labels = ['Bus', 'Car', 'Motorcycle', 'Truck'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08461327-66f0-4a8c-a250-a1099c8eabee",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_per_class = {}\n",
    "accuracy_per_class = {}\n",
    "recall_per_class = {}\n",
    "f1_per_class = {}\n",
    "predictions_all = []\n",
    "ground_truth_all = []\n",
    "\n",
    "for class_name in class_labels:\n",
    "    class_folder = os.path.join(test_image_folder, class_name)\n",
    "    test_images = os.listdir(class_folder)\n",
    "\n",
    "    predictions_class = []\n",
    "    ground_truth_class = [class_name] * len(test_images) \n",
    "\n",
    "    for image_name in test_images:\n",
    "        image_path = os.path.join(class_folder, image_name)\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        predictions = model.predict(preprocessed_image)\n",
    "        predicted_class = class_labels[np.argmax(predictions)]\n",
    "        predictions_all.append(predicted_class)\n",
    "        ground_truth_all.append(class_name)\n",
    "        predictions_class.append(predicted_class)\n",
    "    \n",
    "    accuracy_per_class[class_name] = accuracy_score(ground_truth_class, predictions_class)\n",
    "    precision_per_class[class_name] = precision_score(ground_truth_class, predictions_class, average='weighted', zero_division=1)\n",
    "    recall_per_class[class_name] = recall_score(ground_truth_class, predictions_class, average='weighted', zero_division=1)\n",
    "    f1_per_class[class_name] = f1_score(ground_truth_class, predictions_class, average='weighted', zero_division=1)\n",
    "\n",
    "overall_accuracy = accuracy_score(ground_truth_all, predictions_all)\n",
    "overall_precision = precision_score(ground_truth_all, predictions_all, average='weighted', zero_division=1)\n",
    "overall_recall = recall_score(ground_truth_all, predictions_all, average='weighted', zero_division=1)\n",
    "overall_f1 = f1_score(ground_truth_all, predictions_all, average='weighted', zero_division=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_all, predictions_all)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "for class_name in class_labels:\n",
    "    print(f\"Class: {class_name}\")\n",
    "    print(f\"Accuracy: {accuracy_per_class[class_name]:.2f}\")\n",
    "    print(f\"Recall: {recall_per_class[class_name]:.2f}\")\n",
    "    print(f\"F1 Score: {f1_per_class[class_name]:.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "print(f\"Overall Precision: {overall_precision:.2f}\")\n",
    "print(f\"Overall Recall: {overall_recall:.2f}\")\n",
    "print(f\"Overall F1 Score: {overall_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f748a73-0514-4029-8bd3-648017bbeeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
